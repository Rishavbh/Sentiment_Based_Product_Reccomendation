{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-77b9801f2d70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28382, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"churn_prediction.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.814671\n",
       "1    0.185329\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['churn'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                          0\n",
       "vintage                              0\n",
       "age                                  0\n",
       "gender                             525\n",
       "dependents                        2463\n",
       "occupation                          80\n",
       "city                               803\n",
       "customer_nw_category                 0\n",
       "branch_code                          0\n",
       "current_balance                      0\n",
       "previous_month_end_balance           0\n",
       "average_monthly_balance_prevQ        0\n",
       "average_monthly_balance_prevQ2       0\n",
       "current_month_credit                 0\n",
       "previous_month_credit                0\n",
       "current_month_debit                  0\n",
       "previous_month_debit                 0\n",
       "current_month_balance                0\n",
       "previous_month_balance               0\n",
       "churn                                0\n",
       "last_transaction                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `a) Missing Value Treatment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Gender\n",
    "dict_gender = {'Male': 1, 'Female':0}\n",
    "df.replace({'gender': dict_gender}, inplace = True)\n",
    "\n",
    "# Replace with -1 for missing gender\n",
    "df['gender'] = df['gender'].fillna(-1)\n",
    "\n",
    "# Replacing with max. occurence values\n",
    "df['dependents'] = df['dependents'].fillna(0)\n",
    "df['occupation'] = df['occupation'].fillna('self_employed')\n",
    "df['city'] = df['city'].fillna(1020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `b) Dummy variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert occupation to one hot encoded features\n",
    "df = pd.concat([df,pd.get_dummies(df['occupation'],prefix = str('occupation'),prefix_sep='_')],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>vintage</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>dependents</th>\n",
       "      <th>occupation</th>\n",
       "      <th>city</th>\n",
       "      <th>customer_nw_category</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>current_balance</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_month_debit</th>\n",
       "      <th>current_month_balance</th>\n",
       "      <th>previous_month_balance</th>\n",
       "      <th>churn</th>\n",
       "      <th>last_transaction</th>\n",
       "      <th>occupation_company</th>\n",
       "      <th>occupation_retired</th>\n",
       "      <th>occupation_salaried</th>\n",
       "      <th>occupation_self_employed</th>\n",
       "      <th>occupation_student</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2101</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>187.0</td>\n",
       "      <td>2</td>\n",
       "      <td>755</td>\n",
       "      <td>1458.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1458.71</td>\n",
       "      <td>1458.71</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2348</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3214</td>\n",
       "      <td>5390.37</td>\n",
       "      <td>...</td>\n",
       "      <td>100.56</td>\n",
       "      <td>6496.78</td>\n",
       "      <td>8787.61</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2194</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>salaried</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>3913.16</td>\n",
       "      <td>...</td>\n",
       "      <td>259.23</td>\n",
       "      <td>5006.28</td>\n",
       "      <td>5070.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2329</td>\n",
       "      <td>90</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2</td>\n",
       "      <td>582</td>\n",
       "      <td>2291.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2143.33</td>\n",
       "      <td>2291.91</td>\n",
       "      <td>1669.79</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1579</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>3</td>\n",
       "      <td>388</td>\n",
       "      <td>927.72</td>\n",
       "      <td>...</td>\n",
       "      <td>1538.06</td>\n",
       "      <td>1157.15</td>\n",
       "      <td>1677.16</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  vintage  age  gender  dependents     occupation    city  \\\n",
       "0            1     2101   66     1.0         0.0  self_employed   187.0   \n",
       "1            2     2348   35     1.0         0.0  self_employed  1020.0   \n",
       "2            4     2194   31     1.0         0.0       salaried   146.0   \n",
       "3            5     2329   90    -1.0         0.0  self_employed  1020.0   \n",
       "4            6     1579   42     1.0         2.0  self_employed  1494.0   \n",
       "\n",
       "   customer_nw_category  branch_code  current_balance  ...  \\\n",
       "0                     2          755          1458.71  ...   \n",
       "1                     2         3214          5390.37  ...   \n",
       "2                     2           41          3913.16  ...   \n",
       "3                     2          582          2291.91  ...   \n",
       "4                     3          388           927.72  ...   \n",
       "\n",
       "   previous_month_debit  current_month_balance  previous_month_balance  churn  \\\n",
       "0                  0.20                1458.71                 1458.71      0   \n",
       "1                100.56                6496.78                 8787.61      0   \n",
       "2                259.23                5006.28                 5070.14      0   \n",
       "3               2143.33                2291.91                 1669.79      1   \n",
       "4               1538.06                1157.15                 1677.16      1   \n",
       "\n",
       "   last_transaction  occupation_company  occupation_retired  \\\n",
       "0        2019-05-21                   0                   0   \n",
       "1        2019-11-01                   0                   0   \n",
       "2               NaT                   0                   0   \n",
       "3        2019-08-06                   0                   0   \n",
       "4        2019-11-03                   0                   0   \n",
       "\n",
       "   occupation_salaried  occupation_self_employed  occupation_student  \n",
       "0                    0                         1                   0  \n",
       "1                    0                         1                   0  \n",
       "2                    1                         0                   0  \n",
       "3                    0                         1                   0  \n",
       "4                    0                         1                   0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = df.drop('Attrition', axis=1)\n",
    "x = df.drop(['churn','customer_id', 'occupation', 'last_transaction'], axis=1)\n",
    "y = df['churn']\n",
    "# Splitting the data into train and test\n",
    "X_train,X_test,y_train,y_test=train_test_split(x, y, train_size=0.8, stratify = y, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22705,), (5677,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.814666\n",
       "1    0.185334\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.814691\n",
       "1    0.185309\n",
       "Name: churn, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "Scaler_X = StandardScaler()\n",
    "X_train = Scaler_X.fit_transform(X_train)\n",
    "X_test = Scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling class imbalance using SMOTE based techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) SMOTE Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 18497, 1: 4208})\n",
      "After Counter({0: 18497, 1: 18497})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Before',counter)\n",
    "# oversampling the train dataset using SMOTE\n",
    "smt = SMOTE()\n",
    "#X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_sm)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) ADASYN Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 18497, 1: 4208})\n",
      "After Counter({0: 18497, 1: 17388})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Before',counter)\n",
    "# oversampling the train dataset using ADASYN\n",
    "ada = ADASYN(random_state=130)\n",
    "X_train_ada, y_train_ada = ada.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_ada)\n",
    "print('After',counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Hybrid Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1) SMOTE + Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 18497, 1: 4208})\n",
      "After Counter({0: 18090, 1: 18090})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Before',counter)\n",
    "# oversampling the train dataset using SMOTE + Tomek\n",
    "smtom = SMOTETomek(random_state=139)\n",
    "X_train_smtom, y_train_smtom = smtom.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_smtom)\n",
    "print('After',counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2) SMOTE + ENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 18497, 1: 4208})\n",
      "After Counter({1: 14831, 0: 8943})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print('Before',counter)\n",
    "# oversampling the train dataset using SMOTE + ENN\n",
    "smenn = SMOTEENN()\n",
    "X_train_smenn, y_train_smenn = smenn.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_smenn)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building - Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = list()\n",
    "resample = list()\n",
    "precision = list()\n",
    "recall = list()\n",
    "F1score = list()\n",
    "AUCROC = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(clf_model, X_test, y_test, algo=None, sampling=None):\n",
    "    # Test set prediction\n",
    "    y_prob=clf_model.predict_proba(X_test)\n",
    "    y_pred=clf_model.predict(X_test)\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    print('='*60)\n",
    "    print(confusion_matrix(y_test,y_pred),\"\\n\")\n",
    "    print('Classification Report')\n",
    "    print('='*60)\n",
    "    print(classification_report(y_test,y_pred),\"\\n\")\n",
    "    print('AUC-ROC')\n",
    "    print('='*60)\n",
    "    print(roc_auc_score(y_test, y_prob[:,1]))\n",
    "          \n",
    "    model.append(algo)\n",
    "    precision.append(precision_score(y_test,y_pred))\n",
    "    recall.append(recall_score(y_test,y_pred))\n",
    "    F1score.append(f1_score(y_test,y_pred))\n",
    "    AUCROC.append(roc_auc_score(y_test, y_prob[:,1]))\n",
    "    resample.append(sampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `Original Unsampled Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\mypersonal_mentor\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model=LogisticRegression()\n",
    "\n",
    "params={'C':np.logspace(-10, 1, 15),'class_weight':[None,'balanced'],'penalty':['l1','l2']}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf_LR = GridSearchCV(log_model, params, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "clf_LR.fit(X_train, y_train)\n",
    "clf_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[4596   29]\n",
      " [ 966   86]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90      4625\n",
      "           1       0.75      0.08      0.15      1052\n",
      "\n",
      "    accuracy                           0.82      5677\n",
      "   macro avg       0.79      0.54      0.52      5677\n",
      "weighted avg       0.81      0.82      0.76      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.7734372623574144\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `2.SMOTE Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\mypersonal_mentor\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR.fit(X_train_sm, y_train_sm)\n",
    "clf_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3736  889]\n",
      " [ 334  718]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      4625\n",
      "           1       0.45      0.68      0.54      1052\n",
      "\n",
      "    accuracy                           0.78      5677\n",
      "   macro avg       0.68      0.75      0.70      5677\n",
      "weighted avg       0.83      0.78      0.80      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.7788623985201932\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'smote')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.ADASYN Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\mypersonal_mentor\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR.fit(X_train_ada, y_train_ada)\n",
    "clf_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3914  711]\n",
      " [ 360  692]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88      4625\n",
      "           1       0.49      0.66      0.56      1052\n",
      "\n",
      "    accuracy                           0.81      5677\n",
      "   macro avg       0.70      0.75      0.72      5677\n",
      "weighted avg       0.84      0.81      0.82      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.7786474154763128\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'adasyn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.SMOTE + Tomek Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\mypersonal_mentor\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR.fit(X_train_smtom, y_train_smtom)\n",
    "clf_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3735  890]\n",
      " [ 335  717]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86      4625\n",
      "           1       0.45      0.68      0.54      1052\n",
      "\n",
      "    accuracy                           0.78      5677\n",
      "   macro avg       0.68      0.74      0.70      5677\n",
      "weighted avg       0.83      0.78      0.80      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.7783409721508581\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'smote+tomek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `5.SMOTE + ENN Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\mypersonal_mentor\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight='balanced')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR.fit(X_train_smenn, y_train_smenn)\n",
    "clf_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3721  904]\n",
      " [ 352  700]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.86      4625\n",
      "           1       0.44      0.67      0.53      1052\n",
      "\n",
      "    accuracy                           0.78      5677\n",
      "   macro avg       0.67      0.73      0.69      5677\n",
      "weighted avg       0.83      0.78      0.79      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.7762597883054156\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'smote+enn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-2: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [2,10,30,50,100]\n",
    "# Maximum number of depth in each tree:\n",
    "max_depth = [i for i in range(5,16,2)]\n",
    "# Minimum number of samples to consider to split a node:\n",
    "min_samples_split = [2, 5, 10, 15, 20, 50, 100]\n",
    "# Minimum number of samples to consider at each leaf node:\n",
    "min_samples_leaf = [1, 2, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `1. Original Unsampled Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, min_samples_leaf=2, min_samples_split=100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "\n",
    "tree_param_grid = { \n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "}\n",
    "\n",
    "clf_DT = RandomizedSearchCV(tree_model, tree_param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "clf_DT.fit(X_train, y_train)\n",
    "clf_DT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[4399  226]\n",
      " [ 594  458]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      4625\n",
      "           1       0.67      0.44      0.53      1052\n",
      "\n",
      "    accuracy                           0.86      5677\n",
      "   macro avg       0.78      0.69      0.72      5677\n",
      "weighted avg       0.84      0.86      0.84      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.8025453704655224\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `2.SMOTE Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=11, min_samples_leaf=2, min_samples_split=100)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_DT.fit(X_train_sm, y_train_sm)\n",
    "clf_DT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3607 1018]\n",
      " [ 364  688]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84      4625\n",
      "           1       0.40      0.65      0.50      1052\n",
      "\n",
      "    accuracy                           0.76      5677\n",
      "   macro avg       0.66      0.72      0.67      5677\n",
      "weighted avg       0.81      0.76      0.78      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.775610831363683\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'smote')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.ADASYN Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=9, min_samples_leaf=5, min_samples_split=100)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_DT.fit(X_train_ada, y_train_ada)\n",
    "clf_DT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3741  884]\n",
      " [ 390  662]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.85      4625\n",
      "           1       0.43      0.63      0.51      1052\n",
      "\n",
      "    accuracy                           0.78      5677\n",
      "   macro avg       0.67      0.72      0.68      5677\n",
      "weighted avg       0.82      0.78      0.79      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.7811846675572911\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'adasyn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4. SMOTE + Tomek Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, min_samples_split=20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_DT.fit(X_train_smtom, y_train_smtom)\n",
    "clf_DT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3543 1082]\n",
      " [ 342  710]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83      4625\n",
      "           1       0.40      0.67      0.50      1052\n",
      "\n",
      "    accuracy                           0.75      5677\n",
      "   macro avg       0.65      0.72      0.67      5677\n",
      "weighted avg       0.82      0.75      0.77      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.7847085602712979\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'smote+tomek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `5.SMOTE + ENN Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, min_samples_leaf=5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_DT.fit(X_train_smenn, y_train_smenn)\n",
    "clf_DT.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[2998 1627]\n",
      " [ 257  795]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76      4625\n",
      "           1       0.33      0.76      0.46      1052\n",
      "\n",
      "    accuracy                           0.67      5677\n",
      "   macro avg       0.62      0.70      0.61      5677\n",
      "weighted avg       0.81      0.67      0.70      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.7797787483300791\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_DT, X_test, y_test, 'Decision Tree', 'smote+enn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-3: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `Original Unsampled Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   24.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=11, min_samples_split=15)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_params={'n_estimators':estimators,\n",
    "           'max_depth':max_depth,\n",
    "           'min_samples_split':min_samples_split}\n",
    "\n",
    "clf_RF = RandomizedSearchCV(rf_model, rf_params, cv=cv, scoring='roc_auc', n_jobs=-1, n_iter=20, verbose=2)\n",
    "clf_RF.fit(X_train, y_train)\n",
    "clf_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[4473  152]\n",
      " [ 620  432]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      4625\n",
      "           1       0.74      0.41      0.53      1052\n",
      "\n",
      "    accuracy                           0.86      5677\n",
      "   macro avg       0.81      0.69      0.72      5677\n",
      "weighted avg       0.85      0.86      0.85      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.8275331415065256\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `2.SMOTE Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   27.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=13)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RF.fit(X_train_sm, y_train_sm)\n",
    "clf_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3772  853]\n",
      " [ 351  701]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86      4625\n",
      "           1       0.45      0.67      0.54      1052\n",
      "\n",
      "    accuracy                           0.79      5677\n",
      "   macro avg       0.68      0.74      0.70      5677\n",
      "weighted avg       0.83      0.79      0.80      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.8084634672695509\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'smote')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.ADASYN Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   45.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, n_estimators=50)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RF.fit(X_train_ada, y_train_ada)\n",
    "clf_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3832  793]\n",
      " [ 354  698]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87      4625\n",
      "           1       0.47      0.66      0.55      1052\n",
      "\n",
      "    accuracy                           0.80      5677\n",
      "   macro avg       0.69      0.75      0.71      5677\n",
      "weighted avg       0.83      0.80      0.81      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.8080246634467166\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'adasyn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4. SMOTE + Tomek Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   36.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, n_estimators=10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RF.fit(X_train_smtom, y_train_smtom)\n",
    "clf_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3715  910]\n",
      " [ 378  674]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85      4625\n",
      "           1       0.43      0.64      0.51      1052\n",
      "\n",
      "    accuracy                           0.77      5677\n",
      "   macro avg       0.67      0.72      0.68      5677\n",
      "weighted avg       0.82      0.77      0.79      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.79228660980372\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'smote+tomek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `5. SMOTE + ENN Resampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   20.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=13, min_samples_split=10, n_estimators=30)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RF.fit(X_train_smenn, y_train_smenn)\n",
    "clf_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "============================================================\n",
      "[[3164 1461]\n",
      " [ 242  810]] \n",
      "\n",
      "Classification Report\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.68      0.79      4625\n",
      "           1       0.36      0.77      0.49      1052\n",
      "\n",
      "    accuracy                           0.70      5677\n",
      "   macro avg       0.64      0.73      0.64      5677\n",
      "weighted avg       0.82      0.70      0.73      5677\n",
      " \n",
      "\n",
      "AUC-ROC\n",
      "============================================================\n",
      "0.8008969273455966\n"
     ]
    }
   ],
   "source": [
    "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'smote+enn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_eval_df = pd.DataFrame({'model':model,\n",
    "                            'resample':resample,\n",
    "                            'precision':precision,\n",
    "                            'recall':recall,\n",
    "                            'f1-score':F1score,\n",
    "                            'AUC-ROC':AUCROC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>resample</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>actual</td>\n",
       "      <td>0.747826</td>\n",
       "      <td>0.081749</td>\n",
       "      <td>0.147386</td>\n",
       "      <td>0.773437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.446795</td>\n",
       "      <td>0.682510</td>\n",
       "      <td>0.540053</td>\n",
       "      <td>0.778862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.493229</td>\n",
       "      <td>0.657795</td>\n",
       "      <td>0.563747</td>\n",
       "      <td>0.778647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>smote+tomek</td>\n",
       "      <td>0.446173</td>\n",
       "      <td>0.681559</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>0.778341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>smote+enn</td>\n",
       "      <td>0.436409</td>\n",
       "      <td>0.665399</td>\n",
       "      <td>0.527108</td>\n",
       "      <td>0.776260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>actual</td>\n",
       "      <td>0.669591</td>\n",
       "      <td>0.435361</td>\n",
       "      <td>0.527650</td>\n",
       "      <td>0.802545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.403283</td>\n",
       "      <td>0.653992</td>\n",
       "      <td>0.498912</td>\n",
       "      <td>0.775611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.428202</td>\n",
       "      <td>0.629278</td>\n",
       "      <td>0.509623</td>\n",
       "      <td>0.781185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>smote+tomek</td>\n",
       "      <td>0.396205</td>\n",
       "      <td>0.674905</td>\n",
       "      <td>0.499297</td>\n",
       "      <td>0.784709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>smote+enn</td>\n",
       "      <td>0.328241</td>\n",
       "      <td>0.755703</td>\n",
       "      <td>0.457686</td>\n",
       "      <td>0.779779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>actual</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.410646</td>\n",
       "      <td>0.528117</td>\n",
       "      <td>0.827533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.451094</td>\n",
       "      <td>0.666350</td>\n",
       "      <td>0.537989</td>\n",
       "      <td>0.808463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.468142</td>\n",
       "      <td>0.663498</td>\n",
       "      <td>0.548958</td>\n",
       "      <td>0.808025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>smote+tomek</td>\n",
       "      <td>0.425505</td>\n",
       "      <td>0.640684</td>\n",
       "      <td>0.511381</td>\n",
       "      <td>0.792287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>smote+enn</td>\n",
       "      <td>0.356671</td>\n",
       "      <td>0.769962</td>\n",
       "      <td>0.487511</td>\n",
       "      <td>0.800897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model     resample  precision    recall  f1-score   AUC-ROC\n",
       "0   Logistic Regression       actual   0.747826  0.081749  0.147386  0.773437\n",
       "1   Logistic Regression        smote   0.446795  0.682510  0.540053  0.778862\n",
       "2   Logistic Regression       adasyn   0.493229  0.657795  0.563747  0.778647\n",
       "3   Logistic Regression  smote+tomek   0.446173  0.681559  0.539300  0.778341\n",
       "4   Logistic Regression    smote+enn   0.436409  0.665399  0.527108  0.776260\n",
       "5         Decision Tree       actual   0.669591  0.435361  0.527650  0.802545\n",
       "6         Decision Tree        smote   0.403283  0.653992  0.498912  0.775611\n",
       "7         Decision Tree       adasyn   0.428202  0.629278  0.509623  0.781185\n",
       "8         Decision Tree  smote+tomek   0.396205  0.674905  0.499297  0.784709\n",
       "9         Decision Tree    smote+enn   0.328241  0.755703  0.457686  0.779779\n",
       "10        Random Forest       actual   0.739726  0.410646  0.528117  0.827533\n",
       "11        Random Forest        smote   0.451094  0.666350  0.537989  0.808463\n",
       "12        Random Forest       adasyn   0.468142  0.663498  0.548958  0.808025\n",
       "13        Random Forest  smote+tomek   0.425505  0.640684  0.511381  0.792287\n",
       "14        Random Forest    smote+enn   0.356671  0.769962  0.487511  0.800897"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_eval_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
